{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ryerrabelli/Library/CloudStorage/GoogleDrive-ryerrabelli@gmail.com/My Drive/Computer Backups/Rahul Yerrabelli drive/PythonProjects/EyeTraumaAnalysis/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.ndimage as snd\n",
    "import skimage\n",
    "import uuid\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "directory_path = os.path.abspath(os.path.join(\"src\"))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "\n",
    "import EyeTraumaAnalysis\n",
    "\n",
    "print(directory_path)\n",
    "importlib.reload(EyeTraumaAnalysis);\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import labelbox  # labelbox.Client, MALPredictionImport, LabelImport\n",
    "import labelbox.schema.ontology # OntologyBuilder, Tool, Classification, Option\n",
    "import labelbox.data.annotation_types\n",
    "\"\"\" from labelbox.data.annotation_types import (\n",
    "    Label, ImageData, ObjectAnnotation, MaskData,\n",
    "    Rectangle, Point, Line, Mask, Polygon,\n",
    "    Radio, Checklist, Text,\n",
    "    ClassificationAnnotation, ClassificationAnswer\n",
    ")\"\"\"\n",
    "import labelbox.data.serialization # NDJsonConverter\n",
    "import labelbox.schema.media_type # MediaType\n",
    "\n",
    "import labelbox.schema.queue_mode # QueueMode\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Labelbox API stored in separate file since it is specific for a labelbox\n",
    "#account and shouldn't be committed to git. Contact the\n",
    "# team (i.e. Rahul Yerrabelli) in order to access to the data on your own account.\n",
    "with open(\"auth/LABELBOX_API_KEY.json\", \"r\") as infile:\n",
    "  json_data = json.load(infile)\n",
    "LB_API_KEY = json_data[\"API_KEY\"]\n",
    "del json_data   # delete sensitive info\n",
    "\n",
    "PROJECT_ID = \"clds7rw8a17bd07140ida09o9\"\n",
    "DATASET_ID = \"cldscwrp0071k07zf84smghrw\"\n",
    "ONTOLOGY_ID = \"cldsdg4re1xo707xnbvnadmuw\"\n",
    "\n",
    "client = labelbox.Client(api_key=LB_API_KEY)\n",
    "del LB_API_KEY   # delete sensitive info\n",
    "project = client.get_project(PROJECT_ID)\n",
    "dataset_lb = client.get_dataset(DATASET_ID)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_annotation = labelbox.data.annotation_types.ObjectAnnotation(\n",
    "  name = \"mask\", # must match your ontology feature's name\n",
    "  value = labelbox.data.annotation_types.Mask(mask=mask_data, color=color),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_kmeans(img_bgr, K=10):  # K is number of clusters\n",
    "    #np.all(skimage.io.imread(\"data/01_raw/14579.png\") == skimage.io.imread(data_row.row_data))\n",
    "    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    Z_hsv = img_hsv.reshape((-1,3))\n",
    "    # convert to np.float32\n",
    "    Z_hsv = np.float32(Z_hsv)\n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    ret,label,centers=cv2.kmeans(Z_hsv,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    # Now convert back into uint8, and make original image\n",
    "    centers = np.uint8(centers)\n",
    "    res_hsv = centers[label.flatten()]\n",
    "    res_hsv2 = res_hsv.reshape(img_hsv.shape)\n",
    "    res_bgr = cv2.cvtColor(res_hsv2, cv2.COLOR_HSV2BGR)\n",
    "    # res2 = cv2.cvtColor(res2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "    # sort centers by HSV \"value\" - aka sort by grayscale\n",
    "    centers = centers[centers[:, 2].argsort()]\n",
    "\n",
    "    #centers_indices = np.argsort(centers, axis=0)   # sorts each column separately\n",
    "\n",
    "    kmeans_masks = []\n",
    "    for ind in range(K):\n",
    "        # Can use opencv in range or kmeans\n",
    "        #kmeans_masks.append(cv2.inRange(res_hsv2, centers[ind], centers[ind]))\n",
    "        kmeans_masks.append( np.all(res_hsv2 == centers[ind], axis=-1) )\n",
    "        #kmeans_masks.append( res_hsv2==centers[ind])\n",
    "    kmeans_masks = np.array(kmeans_masks)\n",
    "\n",
    "    # can't make centers a DataFrame until now since needed numpy for opencv in range or numpy comparison\n",
    "    centers = pd.DataFrame(centers, columns=[\"H\",\"S\",\"V\"])\n",
    "    mins = np.array([np.min(img_hsv[kmeans_mask],axis=0) for kmeans_mask in kmeans_masks])\n",
    "    maxs = np.max([np.min(img_hsv[kmeans_mask],axis=0) for kmeans_mask in kmeans_masks])\n",
    "    ranges = pd.DataFrame(maxs - mins, columns=[\"H\",\"S\",\"V\"])\n",
    "    return centers, ranges, res_bgr, kmeans_masks\n",
    "\n",
    "def get_spatial_metrics(mask):\n",
    "    # scipy can perform the mean (center of mass), but not the standard deviation\n",
    "    # spatial_means = snd.center_of_mass(mask)\n",
    "    x = np.linspace(0, 1, mask.shape[1])\n",
    "    y = np.linspace(0, 1, mask.shape[0])\n",
    "    xgrid, ygrid = np.meshgrid(x, y)\n",
    "    grids = {\"x\": xgrid, \"y\":ygrid}\n",
    "    to_return = {\"x\":{}, \"y\":{}}\n",
    "    for ind, grid in grids.items():\n",
    "        to_return[ind][\"mean\"] = np.mean(grids[ind], where=mask.astype(bool))\n",
    "        to_return[ind][\"sd\"] = np.std(grids[ind], where=mask.astype(bool))\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def get_kmeans_metrics(centers, ranges, kmeans_masks):\n",
    "    spatial_metrics_list = [get_spatial_metrics(kmeans_mask) for kmeans_mask in kmeans_masks]\n",
    "    spatial_metrics_pd = pd.concat([pd.DataFrame({\n",
    "        \"x\": [spatial_metrics[\"x\"][\"mean\"] for spatial_metrics in spatial_metrics_list],\n",
    "        \"y\": [spatial_metrics[\"y\"][\"mean\"] for spatial_metrics in spatial_metrics_list],}),\n",
    "        pd.DataFrame({\n",
    "        \"x\": [spatial_metrics[\"x\"][\"sd\"] for spatial_metrics in spatial_metrics_list],\n",
    "        \"y\": [spatial_metrics[\"y\"][\"sd\"] for spatial_metrics in spatial_metrics_list],\n",
    "    })], axis=1, keys=[\"Mean\",\"SD\"])\n",
    "\n",
    "    area_fractions = pd.DataFrame([np.count_nonzero(kmeans_mask)/np.prod(kmeans_mask.shape) for kmeans_mask in\n",
    "                               kmeans_masks], columns=pd.MultiIndex.from_tuples([(\"\",\"\")]))\n",
    "    color_metrics = pd.concat([centers, ranges], axis=1, keys=[\"Center\",\"Range\"])\n",
    "\n",
    "    all_metrics = pd.concat([color_metrics, spatial_metrics_pd, area_fractions], axis=1,\n",
    "                            keys=[\"Color\",\"Location\",\"Area\"])\n",
    "    all_metrics_ranks = np.argsort(all_metrics, axis=0) + 1\n",
    "\n",
    "    return pd.concat([all_metrics, all_metrics_ranks], axis=1, keys=[\"Values\",\"Ranks\"])\n",
    "\n",
    "def choose_kmeans_cluster(metrics):\n",
    "    metrics = metrics.copy()\n",
    "    metrics[(\"Values\",\"Location\",\"SD\",\"x y\")] = metrics[\n",
    "        [(\"Values\",\"Location\",\"SD\",\"x\"),\n",
    "         (\"Values\",\"Location\",\"SD\",\"y\")]].max(axis=1) # get max of x and y SD\n",
    "    likely = metrics[\n",
    "        (metrics[\"Ranks\"][\"Color\"][\"Center\"][\"V\"] >= 5) &\n",
    "        (metrics[\"Values\"][\"Location\"][\"Mean\"][\"x\"] >= 0.3) &\n",
    "        (metrics[\"Values\"][\"Location\"][\"Mean\"][\"x\"] <= 0.7) &\n",
    "        (metrics[\"Values\"][\"Location\"][\"Mean\"][\"y\"] >= 0.3) &\n",
    "        (metrics[\"Values\"][\"Location\"][\"Mean\"][\"y\"] <= 0.7) &\n",
    "        (metrics[\"Values\"][\"Location\"][\"SD\"][\"x\"] <= 0.25) &\n",
    "        (metrics[\"Values\"][\"Location\"][\"SD\"][\"y\"] <= 0.25)\n",
    "    ]\n",
    "    # trim down further\n",
    "    if likely.shape[0] > 2:\n",
    "        likely = likely.sort_values(by=(\"Values\",\"Location\",\"SD\",\"x y\"))[:2]\n",
    "    return likely"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "outputs": [],
   "source": [
    "centers, ranges, res_bgr, kmeans_masks = create_kmeans(img_bgr)\n",
    "metrics = get_kmeans_metrics(centers, ranges, kmeans_masks)\n",
    "chosen = choose_kmeans_cluster(metrics)\n",
    "# get combined masks of the clusters chosen. The .any() applies an OR so only a pixel needs to be in only one cluster\n",
    "# to be included in the combined mask\n",
    "kmeans_masks_chosen = np.any(kmeans_masks[chosen.index],axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "labels = []\n",
    "kmeans_masks_chosens = []\n",
    "\n",
    "for ind, data_row in enumerate(dataset_lb.export_data_rows()):\n",
    "\n",
    "    # read the image from the cloud\n",
    "    img_bgr = skimage.io.imread(data_row.row_data)\n",
    "    # Confirmed that the image from Labelbox is identical to the local image\n",
    "    #np.all(skimage.io.imread(f\"data/01_raw/{data_row.external_id}.png\") == img_bgr)\n",
    "\n",
    "    # apply kmeans on the image and choose the best cluster\n",
    "    centers, ranges, res_bgr, kmeans_masks = create_kmeans(img_bgr)\n",
    "    metrics = get_kmeans_metrics(centers, ranges, kmeans_masks)\n",
    "    chosen = choose_kmeans_cluster(metrics)\n",
    "    # get combined masks of the clusters chosen. The .any() applies an OR so only a pixel needs to be in only one cluster\n",
    "    # to be included in the combined mask\n",
    "    kmeans_masks_chosen = np.any(kmeans_masks[chosen.index],axis=0)\n",
    "    kmeans_masks_chosens.append(kmeans_masks_chosen)\n",
    "\n",
    "    # Append to list of suggested labels\n",
    "    # astype converts from bool to uin8. Has to be uint8 not np.int64; otherwise throws an error since 0-255 not\n",
    "    # guaranteed\n",
    "    lb_mask_data = labelbox.data.annotation_types.MaskData.from_2D_arr(kmeans_masks_chosen.astype(\"uint8\")*255)\n",
    "\n",
    "    color = (28, 230, 255)   # 1CE6FF\n",
    "\n",
    "    lb_mask_data = labelbox.data.annotation_types.MaskData(arr= np.zeros(img_bgr.shape[:2] +(3,),dtype='uint8'))\n",
    "\n",
    "\n",
    "    lb_mask_annotation = labelbox.data.annotation_types.ObjectAnnotation(\n",
    "      name = \"Conjunctiva\", # must match your ontology feature's name\n",
    "      value = labelbox.data.annotation_types.Mask(mask=lb_mask_data, color=color),\n",
    "    )\n",
    "\n",
    "    labels.append(labelbox.data.annotation_types.Label(\n",
    "        data=labelbox.data.annotation_types.ImageData(uid=data_row.uid),\n",
    "        annotations = [ lb_mask_annotation ]\n",
    "    ))\n",
    "\n",
    "    if ind > 1:\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ImageData\na\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mlabelbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mannotation_types\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageData\u001B[49m\u001B[43m(\u001B[49m\u001B[43muid\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43ma\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/EyeTraumaAnalysis/lib/python3.10/site-packages/pydantic/main.py:342\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for ImageData\na\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "labelbox.data.annotation_types.ImageData(uid=\"x\",a=\"a\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "labels[0].annotations[0].value.mask.arr.shape\n",
    "\n",
    "class A:\n",
    "    ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "ImageData(im_bytes=None,file_path=None,url=None,arr=None)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "radio_annotation = labelbox.data.annotation_types.ClassificationAnnotation(\n",
    "  name=\"health\",\n",
    "  value=labelbox.data.annotation_types.Radio(answer = labelbox.data.annotation_types.ClassificationAnswer(name =\n",
    "                                                                                                          \"healthy\"))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "# Convert our label from a Labelbox class object to the underlying NDJSON format required for upload\n",
    "labels_ndjson = list(labelbox.data.serialization.NDJsonConverter.serialize(labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'uuid': '15a42b4d-bd89-43bb-92f2-8bceb8e4b7a3',\n  'dataRow': {'id': 'cldscylxn5fo1071rg0tv4cjj'},\n  'name': 'Conjunctiva',\n  'classifications': [],\n  'mask': {'png': 'iVBORw0KGgoAAAANSUhEUgAAAOcAAABbCAAAAACtl83yAAAAK0lEQVR4nO3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAjwZSeAAB4kP+egAAAABJRU5ErkJggg=='}},\n {'uuid': '2c92f457-76ed-401c-90c9-db83a69fb283',\n  'dataRow': {'id': 'cldscylxn5fnx071rc02rfy8c'},\n  'name': 'Conjunctiva',\n  'classifications': [],\n  'mask': {'png': 'iVBORw0KGgoAAAANSUhEUgAAAOEAAABbCAAAAACgib21AAAAK0lEQVR4nO3BAQ0AAADCoPdPbQ43oAAAAAAAAAAAAAAAAAAAAAAAAACATwNQVgABeIpLqAAAAABJRU5ErkJggg=='}},\n {'uuid': '03a78ef6-649d-4fdf-b899-be37a09d075a',\n  'dataRow': {'id': 'cldscylxn5fnt071r7t6k4o8t'},\n  'name': 'Conjunctiva',\n  'classifications': [],\n  'mask': {'png': 'iVBORw0KGgoAAAANSUhEUgAAAN0AAABZCAAAAACfjn4IAAAAKklEQVR4nO3BMQEAAADCoPVPbQ0PoAAAAAAAAAAAAAAAAAAAAAAAAAAeDU0uAAGxqLOiAAAAAElFTkSuQmCC'}}]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_ndjson"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: [{'uuid': '15a42b4d-bd89-43bb-92f2-8bceb8e4b7a3', 'dataRow': {'id': 'cldscylxn5fo1071rg0tv4cjj'}, 'status': 'FAILURE', 'errors': [{'name': 'InvalidAnnotation', 'message': 'Found empty mask', 'additionalInfo': None}]}, {'uuid': '2c92f457-76ed-401c-90c9-db83a69fb283', 'dataRow': {'id': 'cldscylxn5fnx071rc02rfy8c'}, 'status': 'FAILURE', 'errors': [{'name': 'InvalidAnnotation', 'message': 'Found empty mask', 'additionalInfo': None}]}, {'uuid': '03a78ef6-649d-4fdf-b899-be37a09d075a', 'dataRow': {'id': 'cldscylxn5fnt071r7t6k4o8t'}, 'status': 'FAILURE', 'errors': [{'name': 'InvalidAnnotation', 'message': 'Found empty mask', 'additionalInfo': None}]}]\n"
     ]
    }
   ],
   "source": [
    "# Upload MAL label for this data row in project\n",
    "upload_job = labelbox.MALPredictionImport.create_from_objects(\n",
    "    client = client,\n",
    "    project_id = project.uid,\n",
    "    name=\"mal_job\"+str(uuid.uuid4()),\n",
    "    predictions=labels_ndjson)\n",
    "\n",
    "print(\"Errors:\", upload_job.errors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "MaskData(im_bytes=None,file_path=None,url=None,arr=...)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].annotations[0].value.mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "outputs": [],
   "source": [
    "ontologies = client.get_ontologies(name_contains=\"eye\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Ontology {\n",
      "    \"classification_schema_count\": 0,\n",
      "    \"created_at\": \"2023-02-06 05:27:36.991000+00:00\",\n",
      "    \"description\": null,\n",
      "    \"name\": \"EyeTrauma\",\n",
      "    \"normalized\": {\n",
      "        \"tools\": [\n",
      "            {\n",
      "                \"schemaNodeId\": \"cldsdj2hq40kx071y98ag2lvx\",\n",
      "                \"featureSchemaId\": \"cldsdj2hq40kw071yajag9u0y\",\n",
      "                \"required\": false,\n",
      "                \"name\": \"Conjunctiva\",\n",
      "                \"tool\": \"superpixel\",\n",
      "                \"color\": \"#1CE6FF\",\n",
      "                \"archived\": 0,\n",
      "                \"classifications\": []\n",
      "            },\n",
      "            {\n",
      "                \"schemaNodeId\": \"cldsdj2hq40kz071yhc3yeg6p\",\n",
      "                \"featureSchemaId\": \"cldsdj2hq40ky071y7mz1cuol\",\n",
      "                \"required\": false,\n",
      "                \"name\": \"Pupil center\",\n",
      "                \"tool\": \"point\",\n",
      "                \"color\": \"#FF34FF\",\n",
      "                \"archived\": 0,\n",
      "                \"classifications\": []\n",
      "            }\n",
      "        ],\n",
      "        \"classifications\": [],\n",
      "        \"relationships\": [],\n",
      "        \"realTime\": false\n",
      "    },\n",
      "    \"object_schema_count\": 2,\n",
      "    \"uid\": \"cldsdg4re1xo707xnbvnadmuw\",\n",
      "    \"updated_at\": \"2023-02-06 05:29:54.005000+00:00\"\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "for ont in ontologies:\n",
    "    print(ont)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
